---
name: Overview
---

import LaminarInstall from '/snippets/laminar-install.mdx';
import LaminarInitialize from '/snippets/laminar-initialize.mdx';
import GetProjectApiKey from '/snippets/get-project-api-key.mdx';

Laminar is an open-source LLM engineering platform.

Laminar powers the data flywheel for your LLM applications. With Laminar, you can
trace, evaluate, annotate, analyze, and re-use your LLM data.

Check our [Github repo](https://github.com/lmnr-ai/lmnr) to learn more about how it works or if you are interested in self-hosting.

## Getting started

### Installation

<LaminarInstall />

### Add 2 lines to instrument your code

<LaminarInitialize />

### Project API key

<GetProjectApiKey />

## Example: Instrument OpenAI calls with Laminar

<Tabs>
<Tab title="Python">

```python
import os
from openai import OpenAI
from lmnr import Laminar as L

L.initialize(
    project_api_key=os.environ["LMNR_PROJECT_API_KEY"],
)

client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

def poem_writer(topic: str):
    prompt = f"write a poem about {topic}"

    # OpenAI calls are automatically instrumented
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt},
        ],
    )
    poem = response.choices[0].message.content
    return poem

if __name__ == "__main__":
    print(poem_writer("laminar flow"))
```

</Tab>
<Tab title="JavaScript/TypeScript">

```javascript
import { Laminar as L, observe } from '@lmnr-ai/lmnr';
L.initialize({ projectApiKey: process.env.LMNR_PROJECT_API_KEY });
/// ...
import { OpenAI } from 'openai';

const o = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const poemWriter = async (topic = "turbulence") => {
  const prompt = `write a poem about ${topic}`;

  // OpenAI calls are automatically instrumented
  const response = await o.chat.completions.create({
    model: "gpt-4o",
    messages: [
      { role: "system", content: "You are a helpful assistant." },
      { role: "user", content: prompt }
    ]
  });

  const poem = response.choices[0].message.content;
  return poem;
}

// somewhere in async context
await poemWriter("laminar flow");
await L.shutdown();
```
</Tab>
</Tabs>

### Adding manual instrumentation

If you want to trace your own functions for their durations, inputs and outputs, or want to group 
them into one trace,
you can use `@observe` decorator in Python or async `observe` function in JavaScript/TypeScript.

<Tabs>
<Tab title="Python">

```python
import os
from openai import OpenAI
from lmnr import observe, Laminar as L

L.initialize(project_api_key=os.environ["LMNR_PROJECT_API_KEY"])
client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])

@observe()
def request_handler(data: dict):
    # some other logic, e.g. data preprocessing

    response1 = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": data["prompt_1"]},
        ],
    )

    # some other logic, e.g. a conditional DB call

    response2 = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": data["prompt_2"]},
        ],
    )

    return response2.choices[0].message.content
```
</Tab>
<Tab title="JavaScript/TypeScript">

```javascript
import { OpenAI } from 'openai';
import { Laminar as L, observe } from '@lmnr-ai/lmnr';

L.initialize({ projectApiKey: process.env.LMNR_PROJECT_API_KEY });
const o = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const requestHandler = async (data: Record<string, string>) => 
    await observe({ name: 'requestHandler' }, async () => {
        // some other logic, e.g. data preprocessing

        const response1 = await o.chat.completions.create({
            model: "gpt-4o",
            messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", content: data["prompt_1"] },
            ],
        });

        // some other logic, e.g. a conditional DB call

        const response2 = await o.chat.completions.create({
            model: "gpt-4o",
            messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", content: data["prompt_2"] },
            ],
        });

        return response2.choices[0].message.content;
    });

```
</Tab>
</Tabs>

### Next steps

[Learn more](/tracing/manual-instrumentation#use-observe-to-group-separate-llm-calls-in-one-trace) about
using `observe` and manual instrumentation.


## Features

### Observability

Track the full execution trace of your LLM application.

Laminar's instrumentation is compatible with [OpenTelemetry](https://opentelemetry.io/docs/specs/otel/).

Get started with [Tracing](/tracing/introduction).

![Screenshot of observability dashboard](/images/overview.png)

### Data labeling and analytics

Make sense of thousands of traces generated by your LLM application.

Laminar provides you with a UI where you can label and annotate the traces of your LLM applications.
Multiple team members can label the same spans to measure human agreement. In addition, our online
evaluators can label spans too, so you can measure human alignment of your LLM judge.

You can organize the labeled data into datasets and use them to update your prompts or fine-tune your models.

Learn more about [Data labeling](/labels/introduction) and [Datasets](/datasets/introduction).

### Offline evaluations

Laminar allows you to run your prompts and models against datasets, evaluate the performance, and analyze their
results in the dashboard.

You can use Laminar's JavaScript and Python SDKs to set up and run your evaluations. You are in full control
of the evaluation logic â€“ you can use code or call LLMs of your choice inside your custom evaluators. We store
and visualize the results for you.

Learn more about [offline evaluations](/evaluations/introduction).

### Online evaluations

You can also run evaluations online, i.e. as traces of your production LLM applications come in.

You can create and configure an LLM-as-a-judge evaluator or code-based evaluator from Laminar UI. Then,
Laminar hosts this evaluation logic and runs it with the selection of incoming traces. The results are
stored as labels, and you can use them for further analysis and improvement.

Learn more about [online evaluations](/evaluations/online-evaluations).

### Prompt chain management

You can build and host chains of prompts and LLMs and then call them as if each chain was a single function.
It is especially useful when you want to experiment with techniques, such as Mixture of Agents
and self-reflecting agents, without or before having to manage prompts and model configs in your code.

Learn more about [Pipeline builder](/pipeline/introduction) for prompt chains.
