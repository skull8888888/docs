---
title: "LLM"
description: "Specifications for LLM node"
---

import LLMNodeDescriptionSnippet from '/snippets/llm-node-description-snippet.mdx'
import LLMNodePromptTemplatingSnippet from '/snippets/llm-node-prompt-templating-snippet.mdx'

## LLM node

LLM node executes a prompt and optional chat messages against a selected model (e.g. `gpt-3.5-turbo-16k`).

<LLMNodeDescriptionSnippet node_type="LLM" />

<Frame caption="LLM node with Chat messages">
<img height="300" src="/images/pipeline-builder/llm-with-chat-messages.png" alt="LLM node"/>
</Frame>

## Prompt

<LLMNodePromptTemplatingSnippet />

<Frame>
  <img
    height="300"
    src="/images/pipeline-builder/llm-write-poem.png" alt="LLM node with two template inputs in doubly curly braces"/>
</Frame>

## Supported models

- `gpt-3.5-turbo-16k`
- `gpt-4-turbo-preview`
- `claude-3-haiku`
- `claude-3-sonnet`
- `claude-3-opus`
- `mistral-small`
- `mistral-tiny`

<Tip>If you cannot see required model in this list, check our [Unify node](/nodes/unify), using which you can access almost any model on any provider in few clicks.</Tip>
